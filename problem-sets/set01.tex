\documentclass{homework}
\course{Math 5520H}
\author{Jim Fowler}
\input{preamble}

\begin{document}
\maketitle

\begin{inspiration}
In mathematics, existence is freedom from contradiction.
\byline{David Hilbert}
\end{inspiration}

\section{Terminology}

\begin{problem}\label{terminology:matrix}
  What is a matrix?
\end{problem}

\begin{problem}
  What are elementary row operations?  What does it mean to say that
  two matrices are ``row equivalent'' matrices?
\end{problem}

\begin{problem}\label{homogeneous-linear-equations}
  What is a homogeneous system of linear equations?
\end{problem}

\begin{problem}
  What is an augmented matrix?
\end{problem}

\begin{problem}
  What does it mean to say that a matrix is in ``row echelon'' form?  Reduced row echelon form?
\end{problem}

\begin{problem}\label{definition-rank}
  What is the rank of a matrix?
\end{problem}

\section{Numericals}

\begin{problem}
  Set $v = (1,2,3)$ and $w = (3,2,1)$ and $u = (1,1,1)$.  Find all real
  numbers $\alpha$ and $\beta$ so that $\alpha v + \beta w = u$.
\end{problem}

\begin{problem}
  Find all solutions to the following system of linear equations:
  \begin{align*}
    \phantom{}x+y\phantom{+z+w} &= 1, \\
    \phantom{x+}y+z\phantom{+w} &= 2, \\
    \phantom{x+y+}z+w\phantom{} &= 3, \\
    x+\phantom{y+z+}w\phantom{} &= 4.
  \end{align*}
\end{problem}

\begin{problem}\label{sin-cos-linear-system}Find all $\alpha, \beta \in \R$ so that for all $x \in \R$ we have $\alpha \sin x + \beta \cos x = 0$.  \textit{Hint:}~Relate this to solving a linear system of equations.
\end{problem}

\begin{problem}
  Find all $(x,y,z) \in \R^3$ so that $\alpha^3 x + \alpha^2 y + \alpha z = 0$ for $\alpha \in \{1,2\}$.  What if we instead demand the equation holds for $\alpha \in \{1,2,3\}$?
\end{problem}

\begin{problem}
  Pick your favorite real numbers $x$, $y$, $z$ and row reduce the matrix
  \[
    \begin{pmatrix}
      x^2 & y^2 & z^2 \\
      x^1 & y^1 & z^1 \\
      x^0 & y^0 & z^0            
    \end{pmatrix}.
  \]
  Do it again for some other choice of $x$, $y$, $z$.  Any conjectures?
\end{problem}

\begin{problem}
  A certain matrix $M$ is row equivalent to the matrix
  \[
    \begin{pmatrix}
      1 & 0 & 2 \\
      0 & 1 & 4
    \end{pmatrix}.
  \]
  Describe the solutions to the homogeneous system of linear equations
  associated to $M$.
\end{problem}

\section{Exploration}

\begin{problem}
  Suppose $M$ can be transformed into $N$ by applying elementary row
  operations.  Can you likewise transform $N$ into $M$?
\end{problem}

\begin{solution}
  Yes: each of the row operations can be undone.
\end{solution}

\begin{problem}\label{exploration:quadrilateral-midpoints}
  A quadrilateral in the plane $\R^2$ has vertices $A$, $B$, $C$, and
  $D$.  Let $M_{\overline{AB}}$ be the midpoint of side
  $\overline{AB}$, and similarly define $M_{\overline{BC}}$ and
  $M_{\overline{CD}}$ and $M_{\overline{DA}}$.  Consider the
  quadrilateral having these four midpoints as its vertices; what sort
  of polygon is it?
\end{problem}

\begin{solution}
  Although the original quadrilateral may not be, this is a
  parallelogram.
\end{solution}

\begin{problem}
  Write down a randomly chosen $2$-by-$2$ matrix $M$, and apply row
  operations to find a matrix $N$ in reduced row echelon form which is row
  equivalent to $M$.  What is likely true about $N$?
\end{problem}

\begin{solution}
  A $2$-by-$2$ matrix is, generically, full rank.  Therefore $M$ is
  expected to be the identity matrix.
\end{solution}

\begin{problem}
  When are two $2$-by-$2$ matrices row equivalent?
\end{problem}

\begin{solution}
  The row space is a complete invariant.  
  
  To see why, first consider rank.  Two zero rank $2$-by-$2$ matrices
  are row equivalent, and likewise two full rank $2$-by-$2$ matrices
  are row equivalent.  This handles the cases in which the row space
  is either zero or two dimensional.

  The rank one case is more delicate.  Two rank one $2$-by-$2$
  matrices are row equivalent if their row space is the same.
\end{solution}

\section{Prove or Disprove and Salvage if Possible}

\begin{problem}
  The homogeneous system of linear equations $\mathcal{L}(M)$
  associated with the matrix $M$ has a solution set $S$.  If $N$ is
  another matrix row equivalent to $M$, then the solution set to
  $\mathcal{L}(N)$ is also $S$.
\end{problem}

\begin{solution}
  This is true; to prove it, check that each of the various types of
  row operations can be regarded as ``equation operations'' and do not
  change the solution set.
\end{solution}

\begin{problem}
  Let $M$ and $N$ be matrices which both have $c$ columns, and further
  let $S$ and $T$ be the solution set associated with $\mathcal{L}(M)$
  and $\mathcal{L}(N)$, respectively.  Then the homogeneous system of
  linear equations associated to the block matrix $\begin{pmatrix} M \\
    N \end{pmatrix}$ has solution set $S \cup T$.
\end{problem}

\begin{solution}
  The typo here is  $S \cup T$.  Instead, the solution set is $S \cap T$.
\end{solution}

\begin{problem}
  There exists a nonzero matrix which is row equivalent to the zero matrix.
\end{problem}

\begin{solution}
  This is incorrect; if $M$ is equivalent to the zero matrix, then row operations can be reversed and applied to transform the zero matrix into $M$.  But each of the various types of row operations, applied to the zero matrix, result in the zero matrix.
\end{solution}

\begin{problem}
  There exists a matrix $M$ so that the solution set to $\mathcal{L}(M)$ is empty.
\end{problem}

\begin{solution}
  ``Empty'' should read ``is the set containing only the zero
  vector.''  Then any matrix with trivial kernel is an example.
\end{solution}

\begin{problem}
  Suppose two $m$-by-$n$ matrices $A$ and $B$ have the same rank.
  Then $A$ and $B$ are row equivalent.
\end{problem}

\begin{solution}
  There are various salvages here.  For instance, if $A$ and $B$ are
  square full rank, then $A$ and $B$ are row equivalent.  Another
  salvage is to demonstrate just how wrong this is, perhaps by
  exhibiting infinitely many $2$-by-$2$ rank one matrices which are
  not row equivalent.
\end{solution}

\begin{problem}
  There exists a non-identity matrix which is row equivalent to the identity
  matrix.
\end{problem}

\begin{solution}
  This is true; apply almost any row operation to the identity matrix
  to produce such.
\end{solution}

\begin{problem}
  For every $0 \leq n \leq m$ there exists an $m$-by-$m$ matrix of rank $n$.
\end{problem}

\begin{solution}
  An $m$-by-$m$ diagonal matrix with $n$ ones and $m-n$ zeroes down
  the diagonal is an example of such.
\end{solution}

\begin{problem}
  There exists a symmetric matrix which is row equivalent to a matrix which
  is not symmetric.
\end{problem}

\begin{solution}
  This is true; start with the identity matrix, and add a nonzero
  multiple of one row to another.
\end{solution}

\begin{problem}
  A $3$-by-$3$ matrix is the sum of three rank $1$ matrices.
\end{problem}

\begin{solution}
  In fact, every matrix with $n$ rows is a sum of $n$ rank one
  matrices.
\end{solution}

\begin{problem}
  An $n$-by-$n$ matrix with all entries equal to 1 has rank $n$.
\end{problem}

\begin{solution}
  Rather, an $n$-by-$n$ matrix with all entries equal to 1 has rank
  $1$, because it is row equivalent to a matrix with a single row of
  all ones.
\end{solution}

\begin{problem}
  The sum of rank $n$ matrices has rank $n$.
\end{problem}

\begin{solution}
  One possible salvage is that the sum of rank $n$ can have arbitrary
  rank.  To demonstrate this, add the identity matrix (which has rank
  $n$) to a matrix with $1$'s and $-1$'s down the diagonal.
\end{solution}

\begin{problem}
  Every diagonal matrix is a scalar multiple of the identity matrix.
\end{problem}

\begin{solution}
  The matrix $\begin{bmatrix} 1 & 0 \\ 2 & 0 \end{bmatrix}$ is
  diagonal but not a multiple of the identity matrix.  A perhaps not
  very interesting salvage is to observe that only ``some'' diagonal
  matrices (say a one dimensional family) are scalar multiples of the
  identity.
\end{solution}

\end{document}
