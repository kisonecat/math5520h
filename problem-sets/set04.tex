\documentclass{homework}
\course{Math 5520H}
\author{Jim Fowler}
\input{preamble}

\begin{document}
\maketitle

\begin{inspiration}
  Solving linear systems with constant coefficients is the most
  important technique the students learn in a differential equations
  course.
\byline{Gian-Carlo Rota}
\end{inspiration}

\section{Terminology}

\begin{problem}
  What is a homogeneous differential equation?  Recall \ref{homogeneous-linear-equations}.
\end{problem}

\begin{problem}
  What is an initial value problem?
\end{problem}

\section{Numericals}

\begin{problem}
  Find the general solution to $f''(t) + 5 f'(t) + 6 f(t) = 0$.
\end{problem}

\begin{problem}
  Find the general solution to $f''(t) + 4 f'(t) + 4 f(t) = 0$.
\end{problem}

\begin{problem}\label{resonance-example}Find a solution to $f''(t) + 4 f(t) = \cos (2t)$ where $f(0) = f'(0) = 0$.  Explain why this is an example of \textbf{resonance.}
\end{problem}

\begin{problem}
  Find a solution to $f''(t) + 2f'(t) + f(t) = \cos (2t)$ where $f(0) = f'(0) = 1$.  Identify the \textbf{transient} term.
\end{problem}

\begin{problem}
  Find the general solution to $f^{(4)}(t) + 8\,f''(t) + 16\,f(t) = 0$.
\end{problem}

\begin{problem}
  Find a solution to $f^{(3)}(t) + 3 \, f''(t) + 3 \, f'(t) + f(t) = 0$ such that $f(0) = 1$ and $f'(0) = 2$ and $f''(0) = 3$.
\end{problem}

\section{Exploration}

\begin{problem}\label{independent-exponentials}For which $\lambda, \mu \in \C$ are the functions $f(x) = e^{\lambda x}$ and $g(x) = e^{\mu x}$ linearly independent?
\end{problem}

\begin{solution}
  It suffices that $\lambda \neq \mu$.  Why is this enough?
\end{solution}

\begin{problem}\label{fibonacci-sequence}The vector space of real-valued sequences is denoted $\R^\infty$.
  The shift operator $S : \R^\infty \to \R^\infty$ is defined by
  \[
    S(a_1,a_2,\ldots) = (a_2,a_3,\ldots).
  \]
  The Fibonacci sequence $(1,1,2,3,5,\ldots)$ is in the kernel of $S^2 - S - \id$, which factors as $(S- \phi \cdot \id)(S - \bar{\phi} \cdot \id)$ where $\phi = \frac{1+\sqrt{5}}{2}$ and $\bar{\phi} = \frac{1-\sqrt{5}}{2}$.  Use this to recover \textbf{Binet's formula} computing the $n$th term in the Fibonacci sequence.  
\end{problem}

\begin{solution}
  You should have derived
  \[
    a_n = \frac{1}{\sqrt{5}} \left( \phi^n - \bar{\phi}^n \right).
  \]
  There are lots of fun applications of this formula.  One thing that
  is neat about this is that $\bar{\phi}^n$ is very small, so in
  practice you compute $\phi^n/\sqrt{5}$ and throw away the fractional
  part.
\end{solution}

\begin{problem}\label{shift-repeated-roots}Describe the kernel of $T = S^2 - 4S + 4\id = (S-2\id)^2$.  For
  example, the sequence of powers of two $(2,4,8,\ldots)$ is in the
  kernel of $T$, but is the kernel of $T$ more than one dimensional?
\end{problem}

\begin{solution}
  The sequence $a_n = n 2^n$ is also in the kernel of $T$.  This is because
  \begin{align*}
    (S-2\id)(a_n) &= (n+1) 2^{n+1} - 2 n 2^n \\
                  &= 2 (n+1) 2^{n} - 2 n 2^n \\
                  &= 2^{n+1},
  \end{align*}
  so $(S-2\id)^2(a_n) = 0$.  From the recurrence, the first two terms determine a sequence in the kernel, so $(n 2^n)$ and $2^n$ together span the kernel of $T$.
\end{solution}

\begin{problem}\label{recurrence-differential-analogy}Use \ref{fibonacci-sequence} and \ref{shift-repeated-roots} to
  explain how solving a differential equation is very much like
  solving a recurrence relation.  How does this relate to ``power
  series'' methods for solving differential equations?
\end{problem}

\begin{solution}
  One key insight is to think of the derivative operator as a sort of
  shift on a (formal) power series.
\end{solution}

\begin{problem}\label{introduction-phase-space}Explore how to ``trade dimensions for derivatives'' and make every differential equation into one that involves a single derivative.  In other words, given a differential equation
  \[
    a_n y^{(n)} + a_{n-1} y^{(n-1)} + \cdots + a_1 y' + a_0 y  = 0,
  \]
  repackage $y$ as a vector $\textbf{y}$ so that the above equation becomes $\textbf{y}' = A \textbf{y}$ for a matrix $A$.  How is $A$ related to coefficients $a_i$?  This sheds some light on the significance of \textbf{phase space}.
\end{problem}

\begin{solution}
  Without loss of generality, $a_n = 1$.  In this case, consider
  \[
    \frac{d}{dx} \begin{bmatrix} y_0 \\ \vdots \\ y_{n-1} \end{bmatrix} =
    \begin{bmatrix}
      0 & 1 & 0 & \cdots & 0 & 0\\
      0 & 0 & 1 & \cdots & 0 & 0 \\
        & \vdots &   & \ddots \\
      0 & 0 & 0 & \cdots & 1 & 0\\
      a_0 & a_1 & a_2 & \cdots & a_{n-2} & a_{n-1}
    \end{bmatrix} \begin{bmatrix} y_0 \\ \vdots \\ y_{n-1} \end{bmatrix}
  \]

  
\end{solution}

\begin{problem}\label{introduction-airy-function}The \textbf{Airy function} is a solution to the differential equation
  \[
    f''(x) - x f(x) = 0.
  \]
  We haven't yet shown that solutions exist, but suppose $f_1$ and
  $f_2$ are both solutions to this equation and show $W(f_1,f_2)$
  satisfies a first-order differential equation.  Can you solve that
  equation?  This should be viewed as surprising: there isn't an easy
  formula for the Airy function and yet you can compute the Wronskian
  of \textit{two} solutions to a second-order equation.
\end{problem}

\begin{solution}
  The formula is more straightforward than the problem gives it credit
  for being.   Abel's identity states that, for two solutions to $y'' + p(x)y' + q(x)\,y = 0$, the Wronskian satisfies
  \[
    \displaystyle W(y_{1},y_{2})(x)=W(y_{1},y_{2})(x_{0})\exp {\biggl (}-\int _{x_{0}}^{x}p(t)\,{\textrm {d}}t{\biggr )}
  \]
  But in this case $p(x) = 0$ and $q(x) = -x$, so the Wronskian is simply \textit{constant}.
\end{solution}

\section{Prove or Disprove and Salvage if Possible}

\begin{problem}\label{wrongskian-example}Define $f, g : \R \to \R$ where $f(x) = x^2$ and $g(x) = x |x|$.  Then $\{ f, g \}$ is a linearly independent subset of $C(\R)$.
\end{problem}

\begin{solution}
  This is true.  Suppose $\lambda f + \mu g \equiv 0$.  Then this is true when $x = 1$ and when $x = -1$, meaning that $\lambda + \mu = 0$ and also $\lambda - \mu = 0$.  But therefore $\lambda = \mu = 0$.
\end{solution}

\begin{problem}\label{wronskian-misconception}If the Wronskian of two functions is identically zero, then the
  functions are linearly dependent.
\end{problem}

\begin{solution}
  I like to call this particular mistake the ``Wrong-skian'' and the
  example from \ref{wrongskian-example} is an example.
\end{solution}

\begin{problem}Define $D : C^\infty(\R) \to C^\infty(\R)$ to be the
  derivative operator, i.e., $D(f) = f'$.  For polynomials $p$ and
  $q$, the commutator $[p(D),q(D)]$ vanishes.
\end{problem}

\begin{solution}
  There is nothing special about the role played by $D$ here, other
  than its being a linear operator and this commutativity being a key
  part to our analysis of certain differential operators.

  Let $r$ be the product of polynomials $p$ and $q$.  Then the key
  point is that polynomial multiplication is commutative, meaning that
  \[
    p(D) \cdot q(D) = r(D) = q(D) \cdot p(D),
  \]
  and consequently the commutator vanishes.
\end{solution}

\begin{problem}\label{uniqueness-for-second-order}Suppose $y_1$ and $y_2$ are both solutions to the same second-order linear differential equation with constant coefficients and $y_1(0) = y_2(0)$ and $y'_1(0) = y'_2(0)$.  Then $y_1$ and $y_2$ are identical.
\end{problem}

\begin{solution}
  We proved this in lecture, and a proof is also written down in
  our textbook.
\end{solution}

\begin{problem}\label{wave-equation-orthogonal}Suppose $f_n$ satisfies $f''_n(x) = - n^2 f_n(x)$ and the boundary conditions $f_n(0) = f_n(2\pi)$ and $f'_n(0) = f'_n(2\pi)$ are satisfied, then
  \[
    \int_0^{2\pi} f_n(x) \, f_m(x) \, dx = 0.
  \]
  In other words, $f_n$ and $f_m$ are \textbf{orthogonal}.
\end{problem}

\begin{solution}
  $G_{n,m}(x) = f_n(x) f'_m(x) - f'_n(x) f_m(x)$. Note the quantity $(n^2 - m^2) f_n(x) \, f_m(x)$ equals $G'_{n,m}(x)$, and so
  \[
    (n^2 - m^2) \int_0^{2\pi} f_n(x) \, f_m(x) \, dx = G_{n,m}(2\pi) - G_{n,m}(0),
  \]
  but $G_{n,m}(2\pi) - G_{n,m}(0) = 0$ by the boundary conditions.
\end{solution}

\begin{problem}Define $f_n(x) = \sin \left(nx\right)$.  In the vector
  space of $2\pi$-periodic square-integrable functions, the set
  $\{ f_n : n \in \N \}$ is linearly independent;
  cf.~\ref{sin-cos-indie} and~\ref{definition-inner-product}
  and~\ref{wave-equation-orthogonal}.
\end{problem}

\begin{solution}
  As the references point out, this is follows from the fact that
  orthogonal non-zero vectors are linearly independent.
\end{solution}

\begin{problem}Suppose $y_1$ and $y_2$ are both solutions to
  $y'' + \lambda y = 0$.  Then $y'_1 y_2 - y_1 y'_2$ is constant.
\end{problem}

\begin{solution}
  This is a consequent of Abel's identity (the proof of which, in this
  special case, you should reprise in your write-up here).  But it's
  really just \ref{introduction-airy-function} again.
\end{solution}

\begin{problem}Suppose $y_1$ and $y_2$ are both solutions to
  $y'' + y' + \lambda y = 0$.  Then $y'_1 y_2 - y_1 y'_2$ is constant.
\end{problem}

\begin{solution}
  This isn't quite true, but $y'_1 y_2 - y_1 y'_2 = W(y_1,y_2)$ does
  have a nice form.  For this problem, we are solving $y'' + p(x)y' + q(x)\,y = 0$ with $p(x) = 1$ and $q(x) = \lambda$, so 
  \begin{align*}
    \displaystyle W(y_{1},y_{2})(x)&=W(y_{1},y_{2})(x_{0})\exp {\biggl (}-\int _{x_{0}}^{x}p(t)\,{\textrm {d}}t{\biggr )} \\
    &=W(y_{1},y_{2})(x_{0})\exp (x - x_0).
    \end{align*}
\end{solution}

\begin{problem}
  Suppose $y_1$ and $y_2$ are both solutions to
  $y'' + p y' + q y = 0$ and there exists point $x$ such that $W(y_1,y_2)(x) = 0$.  Then $y_1$ and $y_2$ are linearly dependent.
\end{problem}

\begin{solution}
  We proved this in class, and in fact we proved the stronger
  statement that $y_1$,$y_2$ are linearly independent if and only
  $W(y_1,y_2)(x_0) \neq 0$.
\end{solution}


\end{document}
