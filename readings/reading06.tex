\documentclass{homework}
\input{preamble}
\usepackage{hyperref}
\author{Jim Fowler}
\course{Math 5520H}
\title{Assigned Readings for Week 6}
\date{Monday, September 24, 2018}
\begin{document}
\maketitle

I hope that you have been learning a lot this semester, and that your
strong performance on Midterm~1 reflects how much progress you have
made.  This is an intense course, but always remember that you can
succeed on challenging tasks through your hard work.  Prof.~Gowers
wrote on September 18, 2018:
%https://gowers.wordpress.com/2018/09/09/has-an-uncomfortable-truth-been-suppressed/#comment-361850
\begin{quote}
  I don't deny that there is a link between mathematical ability and
  raw intelligence, but I do think that the link is not as close as is
  popularly believed. And the reason I think that is that the
  correlation I have observed between mathematical success (defined
  not in career terms but in terms of the quality of mathematics
  produced) and raw intelligence (harder to define, but things like an
  unusually good memory and a ``magic'' ability to see things very
  quickly) is weaker than I thought before I became a mathematician.
\end{quote}
In addition to Midterm~1, last week was our introduction to
eigenvectors and eigenvalues.  Along the way, we saw some examples of
diagonalizable operators, and ended the week by noting that operators
on finite dimensional vector spaces, at least over the complex
numbers, can be represented by upper triangular matrices.  Can we do
better than upper triangular?

To see how, read \textit{Linear Algebra: An Introductory Approach} and
look at
\begin{itemize}
\item \textsection 24 The triangular form theorem
\item \textsection 23 The rational and Jordan canonical forms
\end{itemize}
This material is also in Axler's \textit{Linear Algebra Done Right},
for instance, specifically in Chapter~5 and Chapter~8.

Last week, we found that sometimes we do not have enough eigenvectors.
We saw that this was reflected in the \textbf{minimal polynomial}
which will continue to study this week.  To address our lack of
sufficiently many eigenvectors, we introduce \textbf{generalized
  eigenvectors} and generalized eigenspaces.  Quantifying the
difference between eigenvectors and generalized eigenevctors leads to
the notion of \textbf{algebraic versus geometric multiplicity.}

Remember nilpotent matrices from the earlier problem sets?  This week
we meet the \textbf{Jordan-Chevalley decomposition} which expresses an
operator on a finite dimensional complex vector space as a sum of a
diagonal (semisimple) operator and a nilpotent operator.  Exploring in
this way will lead us to discover the \textbf{Jordan canonical
  form}.\footnote{The canonical name for the Jordan canonical form
  ought to be ``canonical'' but unfortunately some people call it the
  ``Jordan normal form.''  I say ``unfortunately'' because the word
  normal is already overloaded---normal subgroup, normal vector\ldots
  and we will be exploring ``normal operators'' in Week~15 of this
  course.}

In your reading, you may note that a matrix satisfies its own characteristic
polynomila, i.e., if $p(\lambda) = \det(A - \lambda I)$, then
$p(A) = 0$.  This is the \textbf{Cayley-Hamilton theorem} and we'll
see it when we focus our attention on determinants, so it should
\textit{not} consume your attention this week.

% minimal polynomial
%algebraic and geometric multiplicity

%Jordan decomposition
%Jordan normal form





\end{document}

